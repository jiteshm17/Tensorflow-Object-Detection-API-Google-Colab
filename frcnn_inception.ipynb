{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "frcnn_inception_resnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUYerQLWU_v0",
        "colab_type": "code",
        "outputId": "0a0ed325-cc87-409d-da3f-07770707b051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-23 07:25:49--  http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 108.177.97.128, 2404:6800:4008:c00::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|108.177.97.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149119618 (142M) [application/x-tar]\n",
            "Saving to: ‘faster_rcnn_inception_v2_coco_2018_01_28.tar.gz’\n",
            "\n",
            "faster_rcnn_incepti 100%[===================>] 142.21M   119MB/s    in 1.2s    \n",
            "\n",
            "2019-07-23 07:25:50 (119 MB/s) - ‘faster_rcnn_inception_v2_coco_2018_01_28.tar.gz’ saved [149119618/149119618]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbQYiOa-VMKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf /content/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jjk-a4PVRtw",
        "colab_type": "code",
        "outputId": "8a23fd5d-dc59-48ba-e991-c9ca12c5fe41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "!git clone https://jiteshm17@bitbucket.org/mohak0/changedtfapi.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'changedtfapi'...\n",
            "remote: Counting objects: 3564, done.\u001b[K\n",
            "remote: Compressing objects: 100% (2801/2801), done.\u001b[K\n",
            "remote: Total 3564 (delta 684), reused 3550 (delta 676)\u001b[K\n",
            "Receiving objects: 100% (3564/3564), 421.11 MiB | 8.24 MiB/s, done.\n",
            "Resolving deltas: 100% (684/684), done.\n",
            "Checking out files: 100% (3658/3658), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HdEYlCzVdDh",
        "colab_type": "code",
        "outputId": "66112707-18b8-4462-b1ef-6f6a37426b00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/changedtfapi/research/object_detection/legacy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/changedtfapi/research/object_detection/legacy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmJ_MSzkVe_4",
        "colab_type": "code",
        "outputId": "47be29d0-6da9-49d1-b9c3-47978eee6afd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTK1MS1eVl9E",
        "colab_type": "code",
        "outputId": "fed7ed76-1ecf-4d57-f257-534170cf6f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py --logtostderr --train_dir=/content/drive/My\\ Drive/ocr_resized_train_checkpoints/ --pipeline_config_path=/content/frcnn_inception.config\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0719 14:12:47.122442 140446143244160 learning.py:507] global step 26744: loss = 0.1192 (1.177 sec/step)\n",
            "I0719 14:12:48.289845 140446143244160 learning.py:507] global step 26745: loss = 0.1373 (1.166 sec/step)\n",
            "I0719 14:12:49.509042 140446143244160 learning.py:507] global step 26746: loss = 0.1665 (1.217 sec/step)\n",
            "I0719 14:12:50.703899 140446143244160 learning.py:507] global step 26747: loss = 0.0978 (1.193 sec/step)\n",
            "I0719 14:12:51.927243 140446143244160 learning.py:507] global step 26748: loss = 0.1513 (1.221 sec/step)\n",
            "I0719 14:12:53.141023 140446143244160 learning.py:507] global step 26749: loss = 0.0734 (1.212 sec/step)\n",
            "I0719 14:12:54.327282 140446143244160 learning.py:507] global step 26750: loss = 0.2177 (1.184 sec/step)\n",
            "I0719 14:12:55.509755 140446143244160 learning.py:507] global step 26751: loss = 0.0198 (1.181 sec/step)\n",
            "I0719 14:12:56.701880 140446143244160 learning.py:507] global step 26752: loss = 0.0415 (1.190 sec/step)\n",
            "I0719 14:12:57.866882 140446143244160 learning.py:507] global step 26753: loss = 0.1590 (1.163 sec/step)\n",
            "I0719 14:12:59.090111 140446143244160 learning.py:507] global step 26754: loss = 0.0964 (1.221 sec/step)\n",
            "I0719 14:13:00.280549 140446143244160 learning.py:507] global step 26755: loss = 0.1655 (1.188 sec/step)\n",
            "I0719 14:13:01.470958 140446143244160 learning.py:507] global step 26756: loss = 0.4522 (1.188 sec/step)\n",
            "I0719 14:13:02.660218 140446143244160 learning.py:507] global step 26757: loss = 0.0741 (1.187 sec/step)\n",
            "I0719 14:13:03.836302 140446143244160 learning.py:507] global step 26758: loss = 0.2473 (1.174 sec/step)\n",
            "I0719 14:13:05.026774 140446143244160 learning.py:507] global step 26759: loss = 0.1565 (1.188 sec/step)\n",
            "I0719 14:13:06.214293 140446143244160 learning.py:507] global step 26760: loss = 0.2052 (1.185 sec/step)\n",
            "I0719 14:13:07.460447 140446143244160 learning.py:507] global step 26761: loss = 0.1942 (1.244 sec/step)\n",
            "I0719 14:13:08.673189 140446143244160 learning.py:507] global step 26762: loss = 0.1229 (1.210 sec/step)\n",
            "I0719 14:13:09.872946 140446143244160 learning.py:507] global step 26763: loss = 0.1189 (1.197 sec/step)\n",
            "I0719 14:13:11.046861 140446143244160 learning.py:507] global step 26764: loss = 0.1807 (1.172 sec/step)\n",
            "I0719 14:13:12.242130 140446143244160 learning.py:507] global step 26765: loss = 0.0197 (1.193 sec/step)\n",
            "I0719 14:13:13.456974 140446143244160 learning.py:507] global step 26766: loss = 0.0864 (1.213 sec/step)\n",
            "I0719 14:13:14.658587 140446143244160 learning.py:507] global step 26767: loss = 0.0694 (1.200 sec/step)\n",
            "I0719 14:13:15.846128 140446143244160 learning.py:507] global step 26768: loss = 0.1749 (1.186 sec/step)\n",
            "I0719 14:13:17.037016 140446143244160 learning.py:507] global step 26769: loss = 0.3184 (1.189 sec/step)\n",
            "I0719 14:13:18.223187 140446143244160 learning.py:507] global step 26770: loss = 0.1189 (1.183 sec/step)\n",
            "I0719 14:13:19.405351 140446143244160 learning.py:507] global step 26771: loss = 0.1451 (1.181 sec/step)\n",
            "I0719 14:13:20.579300 140446143244160 learning.py:507] global step 26772: loss = 0.1906 (1.172 sec/step)\n",
            "I0719 14:13:21.811145 140446143244160 learning.py:507] global step 26773: loss = 0.1282 (1.229 sec/step)\n",
            "I0719 14:13:23.042689 140446143244160 learning.py:507] global step 26774: loss = 0.1801 (1.229 sec/step)\n",
            "I0719 14:13:24.247309 140446143244160 learning.py:507] global step 26775: loss = 0.1235 (1.202 sec/step)\n",
            "I0719 14:13:25.428054 140446143244160 learning.py:507] global step 26776: loss = 0.1344 (1.179 sec/step)\n",
            "I0719 14:13:26.607486 140446143244160 learning.py:507] global step 26777: loss = 0.1850 (1.177 sec/step)\n",
            "I0719 14:13:27.788608 140446143244160 learning.py:507] global step 26778: loss = 0.1749 (1.179 sec/step)\n",
            "I0719 14:13:28.994233 140446143244160 learning.py:507] global step 26779: loss = 0.1549 (1.203 sec/step)\n",
            "I0719 14:13:30.226076 140446143244160 learning.py:507] global step 26780: loss = 0.0925 (1.230 sec/step)\n",
            "I0719 14:13:31.421871 140446143244160 learning.py:507] global step 26781: loss = 0.1754 (1.193 sec/step)\n",
            "I0719 14:13:32.611634 140446143244160 learning.py:507] global step 26782: loss = 0.2278 (1.188 sec/step)\n",
            "I0719 14:13:33.801315 140446143244160 learning.py:507] global step 26783: loss = 0.2310 (1.188 sec/step)\n",
            "I0719 14:13:34.968575 140446143244160 learning.py:507] global step 26784: loss = 0.0092 (1.165 sec/step)\n",
            "I0719 14:13:36.192332 140446143244160 learning.py:507] global step 26785: loss = 0.0204 (1.222 sec/step)\n",
            "I0719 14:13:37.431904 140446143244160 learning.py:507] global step 26786: loss = 0.1514 (1.237 sec/step)\n",
            "I0719 14:13:38.606266 140446143244160 learning.py:507] global step 26787: loss = 0.1474 (1.172 sec/step)\n",
            "I0719 14:13:39.785741 140446143244160 learning.py:507] global step 26788: loss = 0.1392 (1.178 sec/step)\n",
            "I0719 14:13:40.960843 140446143244160 learning.py:507] global step 26789: loss = 0.0268 (1.173 sec/step)\n",
            "I0719 14:13:42.163767 140446143244160 learning.py:507] global step 26790: loss = 0.1614 (1.201 sec/step)\n",
            "I0719 14:13:43.360271 140446143244160 learning.py:507] global step 26791: loss = 0.1251 (1.194 sec/step)\n",
            "I0719 14:13:44.564504 140446143244160 learning.py:507] global step 26792: loss = 0.0782 (1.202 sec/step)\n",
            "I0719 14:13:45.769297 140446143244160 learning.py:507] global step 26793: loss = 0.1110 (1.203 sec/step)\n",
            "I0719 14:13:46.960743 140446143244160 learning.py:507] global step 26794: loss = 0.1858 (1.189 sec/step)\n",
            "I0719 14:13:48.138776 140446143244160 learning.py:507] global step 26795: loss = 0.1463 (1.176 sec/step)\n",
            "I0719 14:13:49.324224 140446143244160 learning.py:507] global step 26796: loss = 0.0575 (1.184 sec/step)\n",
            "I0719 14:13:50.551031 140446143244160 learning.py:507] global step 26797: loss = 0.1466 (1.225 sec/step)\n",
            "I0719 14:13:51.752235 140446143244160 learning.py:507] global step 26798: loss = 0.1064 (1.199 sec/step)\n",
            "I0719 14:13:52.990335 140446143244160 learning.py:507] global step 26799: loss = 0.1198 (1.235 sec/step)\n",
            "I0719 14:13:54.181813 140446143244160 learning.py:507] global step 26800: loss = 0.1529 (1.189 sec/step)\n",
            "I0719 14:13:55.404693 140446143244160 learning.py:507] global step 26801: loss = 0.0935 (1.221 sec/step)\n",
            "I0719 14:13:56.590784 140446143244160 learning.py:507] global step 26802: loss = 0.2951 (1.184 sec/step)\n",
            "I0719 14:13:57.764566 140446143244160 learning.py:507] global step 26803: loss = 0.2736 (1.172 sec/step)\n",
            "I0719 14:13:59.079478 140446143244160 learning.py:507] global step 26804: loss = 0.2011 (1.311 sec/step)\n",
            "I0719 14:14:01.036084 140446143244160 learning.py:507] global step 26805: loss = 0.3482 (1.918 sec/step)\n",
            "I0719 14:14:02.895567 140446143244160 learning.py:507] global step 26806: loss = 0.1632 (1.839 sec/step)\n",
            "I0719 14:14:04.825663 140446143244160 learning.py:507] global step 26807: loss = 0.2261 (1.739 sec/step)\n",
            "I0719 14:14:04.851289 140443167786752 supervisor.py:1050] Recording summary at step 26807.\n",
            "I0719 14:14:06.018635 140446143244160 learning.py:507] global step 26808: loss = 0.3206 (1.189 sec/step)\n",
            "I0719 14:14:07.201453 140446143244160 learning.py:507] global step 26809: loss = 0.0610 (1.181 sec/step)\n",
            "I0719 14:14:08.387529 140446143244160 learning.py:507] global step 26810: loss = 0.0812 (1.185 sec/step)\n",
            "I0719 14:14:09.586452 140446143244160 learning.py:507] global step 26811: loss = 0.2841 (1.197 sec/step)\n",
            "I0719 14:14:10.771261 140446143244160 learning.py:507] global step 26812: loss = 0.1052 (1.183 sec/step)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geq_pUkdWhT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}